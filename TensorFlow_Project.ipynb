{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git commands in Git Bash to push commits in GitHub\n",
    "##cd Personal/Self_Study/Projects/MyProject\n",
    "##git add TensorFlow_Project.ipynb\n",
    "##git commit -m \"Update code\"\n",
    "##git push\n",
    "##Useful link: https://readwrite.com/2013/09/30/understanding-github-a-journey-for-beginners-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example code to understand how tensorflow works for Deep Neural Networks (DNN)\n",
    "#with made up xy data for regression model\n",
    "\n",
    "\n",
    "#imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "#define the NN\n",
    "##this function builds a models with one hidden layer and just one neuron with one input value\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])\n",
    "#compile the NN\n",
    "##this function tries to learn by \n",
    "##1. starting with a random relation beween the input and output\n",
    "##2. calculating the difference between real and estimated output (loss)\n",
    "##3. changing the relation in order to reduce the loss (optimizer)\n",
    "##4. repeat steps 2 and 3 for the number of epochs\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "\n",
    "#providing the data\n",
    "##the exact relation is y = (2*x)-1\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
    "\n",
    "#training the NN\n",
    "model.fit(xs,ys,epochs=500)\n",
    "\n",
    "#try to predict\n",
    "##the exact value is (2*10)-1 = 19\n",
    "print(model.predict(np.array([10.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example code to understand how tensorflow works\n",
    "#dataset from fashionMNIST (curated by Zalando) using its API in tensorflow\n",
    "#this is classification problem with 28X28 pixel grayscale images of clothes as input and labels as output\n",
    "#each pixel can take any value from 0 to 255\n",
    "\n",
    "#imports\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "#dataset\n",
    "#get the fashionMNIST data from the tensorflow API\n",
    "mnist = tf.keras.datasets.fashion_mnist #create an object to get the data\n",
    "#there are about 70K data entries out of which 60K is automatically allocated for training and 10K is allocated for testing\n",
    "(trainingImages,trainingLabels),(testImages,testLabels) = mnist.load_data() #load train and test data from object\n",
    "#visualizing the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "imgNum = 7\n",
    "plt.imshow(trainingImages[imgNum])\n",
    "print(trainingLabels[imgNum])\n",
    "print(trainingImages[imgNum])\n",
    "#normalizing the data to enable better learning of the model\n",
    "trainingImages = trainingImages/255.0\n",
    "testImages = testImages/255.0\n",
    "\n",
    "#print(len([item for sublist in trainingImages[imgNum] for item in sublist]))\n",
    "\n",
    "\n",
    "#define the NN model\n",
    "##Sequential: That defines a SEQUENCE of layers in the neural network\n",
    "##Flatten: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
    "##Dense: Adds a layer of neurons\n",
    "##Each layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n",
    "##Relu effectively means \"If X>0 return X, else return 0\" -- so what it does is it only passes values 0 or greater to the next layer in the network.\n",
    "##Softmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),tf.keras.layers.Dense(128,activation=tf.nn.relu),tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n",
    "\n",
    "#compile the NN model\n",
    "##what are the different optimizer and loss parameters???\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#train the NN model with the training data\n",
    "model.fit(trainingImages,trainingLabels,epochs=5)\n",
    "\n",
    "#evaluating the model with the test data\n",
    "model.evaluate(testImages,testLabels)\n",
    "\n",
    "\n",
    "# #using callbacks to terminate the program when a desired accuracy is reached\n",
    "# desiredAcc = 0.6\n",
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#   def on_epoch_end(self, epoch, logs={}):\n",
    "#     if(logs.get('loss')<(1-desiredAcc)):\n",
    "#       print(\"\\nReached desired accuracy so cancelling training!\")\n",
    "#       self.model.stop_training = True\n",
    "\n",
    "# callbacks = myCallback()\n",
    "\n",
    "# model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
    "\n",
    "\n",
    "\n",
    "#parameters that can change\n",
    "##training test dataset distribution\n",
    "##NN architecture - number of hidden layers and neurons in each layer\n",
    "##normalization of data\n",
    "##number of iterations (epochs)\n",
    "##optimizer used\n",
    "##loss function used\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using callbacks to terminate the program when a desired accuracy is reached\n",
    "\n",
    "desiredAcc = 0.7 #1 is 100% accuracy\n",
    "\n",
    "#create a class for the callback which will take the log and check for a certain condition\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "#its good to use epoch_end since sometimes loss drops over a small data range but not on the whole data\n",
    "  def on_epoch_end(self, epoch, logs={}): \n",
    "    if(logs.get('loss')<(1-desiredAcc)):\n",
    "      print(\"\\nReached desired accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "#instantiating the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(trainingImages,trainingLabels),(testImages,testLabels) = mnist.load_data()\n",
    "trainingImages = trainingImages/255.0\n",
    "testImages = testImages/255.0\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),tf.keras.layers.Dense(128,activation=tf.nn.relu),tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainingImages, trainingLabels, epochs=10, callbacks=[callbacks]) # use callback as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Flatten argument can be used with exact shape of the input\n",
    "#the accuracy can be selected instead of the loss value in the callback function\n",
    "#using callbacks to terminate the program when a desired accuracy is reached\n",
    "\n",
    "desiredAcc = 0.9 #1 is 100% accuracy\n",
    "\n",
    "#create a class for the callback which will take the log and check for a certain condition\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "#its good to use epoch_end since sometimes loss drops over a small data range but not on the whole data\n",
    "  def on_epoch_end(self, epoch, logs={}): \n",
    "    if(logs.get('acc')>desiredAcc):\n",
    "      print(\"\\nReached desired accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "#instantiating the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(trainingImages,trainingLabels),(testImages,testLabels) = mnist.load_data()\n",
    "trainingImages = trainingImages/255.0\n",
    "testImages = testImages/255.0\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),tf.keras.layers.Dense(128,activation=tf.nn.relu),tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainingImages, trainingLabels, epochs=10, callbacks=[callbacks]) # use callback as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN:\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.5030 - acc: 0.8228\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.3810 - acc: 0.8630\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3395 - acc: 0.8755\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3146 - acc: 0.8854\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2969 - acc: 0.8902\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "CNN & Pooling\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#DNN are powerful for learning\n",
    "#convolutions are filters applied to the data to highlight label-specific features\n",
    "#adding convolutions to DNN to generates Convoluted Neural Networks (CNN)\n",
    "#another useful filter to compress data is called pooling, which reduces the data by different logics\n",
    "\n",
    "#the FMNIST example\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(trainImages,trainLabels),(testImages,testLabels) = mnist.load_data()\n",
    "#normalizing data to lie between 0 and 1\n",
    "trainImages = trainImages/255.0\n",
    "testImages = testImages/255.0\n",
    "\n",
    "\n",
    "#DNN\n",
    "print(\"DNN:\")\n",
    "#define model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "#train model\n",
    "model.fit(trainImages,trainLabels,epochs=5)\n",
    "#evaluate model\n",
    "testLoss = model.evaluate(testImages,testLabels)\n",
    "\n",
    "\n",
    "#CNN and pooling\n",
    "##using convolutions is similar to applying filters to images (like this: https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
    "##CNN may give better fit than DNN but care should be taken not to overfit\n",
    "print(\"CNN & Pooling\")\n",
    "#data formating\n",
    "##Step 1 is to gather the data. You'll notice that there's a bit of a change here in that the training data needed to be reshaped. That's because the first convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 items in a list, we have a single 4D list that is 60,000x28x28x1, and the same for the test images. If you don't do this, you'll get an error when training as the Convolutions do not recognize the shape. \n",
    "(trainImages,trainLabels),(testImages,testLabels) = mnist.load_data()\n",
    "trainImages = trainImages.reshape(60000,28,28,1)\n",
    "trainImages = trainImages/255.0\n",
    "testImages = testImages.reshape(10000,28,28,1)\n",
    "testImages = testImages/255.0\n",
    "#define model\n",
    "##Next is to define your model. Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
    "## 1.The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
    "## 2. The size of the Convolution, in this case a 3x3 grid\n",
    "## 3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
    "## 4. In the first layer, the shape of the input data.\n",
    "##You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%.\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#You can call model.summary() to see the size and shape of the network, and you'll notice that after every MaxPooling layer, the image size is reduced in this way. \n",
    "model.summary()\n",
    "model.fit(trainImages, trainLabels, epochs=5) #very slow step since convolutions computation is 2X64X60000X26X26 and pooling computation is 2X60000X13X13\n",
    "test_loss = model.evaluate(testImages, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the Convolutions and Pooling\n",
    "##This code will show us the convolutions graphically. The print (test_labels[:100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution/pooling combination.\n",
    "#print(testLabels[:100])\n",
    "labelID = 9\n",
    "labelSet = [i for i,val in enumerate(testLabels[:100]) if val==labelID] #enumerate returns the index and value of the list\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.imshow(testImages[labelSet])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=labelSet[0]\n",
    "SECOND_IMAGE=labelSet[1]\n",
    "THIRD_IMAGE=labelSet[2]\n",
    "CONVOLUTION_NUMBER = 0\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(testImages[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(testImages[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(testImages[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
